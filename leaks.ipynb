{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maplib import Mapping\n",
    "import polars as pl\n",
    "pl.Config.set_fmt_str_lengths(300)\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a1c7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pan = \"https://github.com/DataTreehouse/maplib_workshop/pan#\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdf231a",
   "metadata": {},
   "source": [
    "### There are three date formats, so we have to do some work.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b746fe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_format_1 = \"%d-%b-%Y\"\n",
    "date_format_2 = \"%b %d, %Y\" \n",
    "date_format_3 = \"%Y-%m-%d\"\n",
    "date_formats = [date_format_1, date_format_2, date_format_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eed3ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dates(lf, colname, check=False):\n",
    "    new_cols = []\n",
    "    for (i,date_format) in enumerate(date_formats):\n",
    "        new_col = f\"{colname}{i}\"\n",
    "        new_cols.append(new_col)\n",
    "        lf = lf.with_columns(\n",
    "            pl.col(colname).str.to_date(format=date_format, strict=False).alias(new_col)\n",
    "        )\n",
    "    lf = lf.with_columns(\n",
    "        pl.coalesce(new_cols).alias(colname + \"_new\")\n",
    "    ).drop(new_cols)\n",
    "    if check:\n",
    "        df = lf.collect()\n",
    "        df = df.filter(pl.col(colname + \"_new\").is_null() & ~(pl.col(colname).is_null()))\n",
    "        if df.height > 0:\n",
    "            print(\"Unparsed dates:\")\n",
    "            print(df[colname])\n",
    "            assert False\n",
    "    lf = lf.drop(colname).with_columns(pl.col(colname + \"_new\").alias(colname)).drop(colname + \"_new\")\n",
    "    return lf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d2df6d",
   "metadata": {},
   "source": [
    "### More utility functions for data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f779fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_to_list_column(lf, colname, newname):\n",
    "    lf = lf.with_columns(pl.col(colname).str.split(\";\").alias(newname)).drop(colname)\n",
    "    return lf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9945e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_node_id_uri(lf, node_id_col):\n",
    "    lf = lf.with_columns(\n",
    "        (\"https://github.com/DataTreehouse/maplib_workshop/node_ids#\" + pl.col(node_id_col).cast(pl.Utf8)).alias(node_id_col))\n",
    "    return lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d56168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(lf, col):\n",
    "    lf = lf.with_columns(\n",
    "        pl.col(col).\n",
    "        str.replace_all(\"\\\"\", \"\", literal=True).\n",
    "        str.replace_all(\"\\n\", \" \", literal=True).\n",
    "        str.replace_all(\"\\\\\", \"\", literal=True).\n",
    "        str.replace_all(\"\\uFFFD\", \"\", literal=True).\n",
    "        str.replace_all(\"%\", \"\", literal=True)\n",
    "    )\n",
    "    return lf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4213709d",
   "metadata": {},
   "source": [
    "### We can read and prepare the (legal) entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abd2e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_lf = pl.scan_parquet(\"offshoreleaks/nodes-entities.parquet\")\n",
    "for date_col in [\"incorporation_date\", \"inactivation_date\", \"struck_off_date\", \"dorm_date\"]:\n",
    "    entities_lf = parse_dates(entities_lf, date_col, check=False)\n",
    "entities_lf = create_node_id_uri(entities_lf, \"node_id\")\n",
    "entities_lf = split_to_list_column(entities_lf, \"countries\", \"country\")\n",
    "entities_lf = clean_string(entities_lf, \"name\")\n",
    "entities_lf = entities_lf.select([\n",
    "    \"node_id\", \"name\", \"incorporation_date\", \"inactivation_date\", \"struck_off_date\", \"status\", \"country\", \"service_provider\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ac54e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_df = entities_lf.collect()\n",
    "entities_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775e44f5",
   "metadata": {},
   "source": [
    "### We read and prepare the addresses of individuals and organizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d70748",
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses_lf = pl.scan_parquet(\"offshoreleaks/nodes-addresses.parquet\")\n",
    "addresses_lf = create_node_id_uri(addresses_lf, \"node_id\")\n",
    "addresses_lf = split_to_list_column(addresses_lf, \"countries\", \"country\")\n",
    "addresses_lf = addresses_lf.drop_nulls(\"address\")\n",
    "addresses_lf = clean_string(addresses_lf, \"address\")\n",
    "addresses_lf = addresses_lf.select([\"node_id\", \"address\", \"country\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0463d244",
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses_df = addresses_lf.collect()\n",
    "addresses_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccc3599",
   "metadata": {},
   "source": [
    "### Read and prepare table of intermediaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15598ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediaries_lf = pl.scan_parquet(\"offshoreleaks/nodes-intermediaries.parquet\")\n",
    "intermediaries_lf = create_node_id_uri(intermediaries_lf, \"node_id\")\n",
    "intermediaries_lf = split_to_list_column(intermediaries_lf, \"countries\", \"country\")\n",
    "intermediaries_lf = clean_string(intermediaries_lf, \"name\")\n",
    "intermediaries_lf = intermediaries_lf.select([\"node_id\", \"name\", \"status\", \"country\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e814a8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediaries_df = intermediaries_lf.collect()\n",
    "intermediaries_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de39451",
   "metadata": {},
   "source": [
    "### Read and prepare the table of officers, e.g. CFOs, CEOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34f67e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "officers_lf = pl.scan_parquet(\"offshoreleaks/nodes-officers.parquet\")\n",
    "officers_lf = split_to_list_column(officers_lf, \"countries\", \"country\")\n",
    "officers_lf = create_node_id_uri(officers_lf, \"node_id\")\n",
    "officers_lf = clean_string(officers_lf, \"name\")\n",
    "officers_lf = officers_lf.select([\"node_id\", \"name\", \"country\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c03fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "officers_df = officers_lf.collect()\n",
    "officers_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2ab05c",
   "metadata": {},
   "source": [
    "### There are a few other nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143b1456",
   "metadata": {},
   "outputs": [],
   "source": [
    "others_lf = pl.scan_csv(\"offshoreleaks/nodes-others.csv\", dtypes={\"internal_id\":pl.Utf8})\n",
    "others_lf = split_to_list_column(others_lf, \"countries\", \"country\")\n",
    "others_lf = create_node_id_uri(others_lf, \"node_id\")\n",
    "others_lf = clean_string(others_lf,\"name\")\n",
    "others_lf = others_lf.select([\"node_id\", \"name\", \"country\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7ca886",
   "metadata": {},
   "outputs": [],
   "source": [
    "others_df = others_lf.collect()\n",
    "others_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8803d3ea",
   "metadata": {},
   "source": [
    "### Now we prepare the relationships between nodes, these require quite a bit of cleaning up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963f2e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "relationships_lf = pl.scan_parquet(\"offshoreleaks/relationships.parquet\")\n",
    "relationships_lf = create_node_id_uri(relationships_lf, \"node_id_start\")\n",
    "relationships_lf = create_node_id_uri(relationships_lf, \"node_id_end\")\n",
    "relationships_lf = relationships_lf.with_columns(\n",
    "    pl.col(\"link\").\n",
    "    str.replace_all(\" / \", \",\", literal=True).\n",
    "    str.replace_all(\"/\", \",\", literal=True).\n",
    "    str.replace_all(\" - \", \",\", literal=True).\n",
    "    str.replace_all(\" & \", \",\", literal=True).\n",
    "    str.replace_all(\";\", \",\", literal=True)\n",
    ")\n",
    "relationships_lf = clean_string(relationships_lf, \"link\").with_columns(\n",
    "    pl.col(\"link\").str.split(\",\")).explode(\"link\")\n",
    "relationships_lf = relationships_lf.with_columns(\n",
    "    pl.col(\"link\").\n",
    "    str.strip().\n",
    "    str.to_lowercase().\n",
    "    str.replace_all(\" \", \"_\", literal=True).\n",
    "    str.replace_all(\"[\\W\\.\\n0-9]\", \"\", literal=False)\n",
    ")\n",
    "relationships_lf = relationships_lf.with_columns(\n",
    "    pl.when(pl.col(\"link\").str.n_chars() < 2).then(\"unknown\").otherwise(pl.col(\"link\"))\n",
    ")\n",
    "relationships_lf = relationships_lf.with_columns(\n",
    "    (pan + pl.col(\"rel_type\")).alias(\"rel_type\"),\n",
    "    (pan + pl.col(\"link\")).alias(\"link\")\n",
    ")\n",
    "relationships_lf = relationships_lf.select([\"node_id_start\", \"node_id_end\", \"link\", \"rel_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1628dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "relationships_df = relationships_lf.collect()\n",
    "relationships_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556d663d",
   "metadata": {},
   "source": [
    "### We define templates to instantiate triples using stOTTR, which is terse syntax for OTTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df97b582",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"\"\"\n",
    "@prefix pan:<https://github.com/DataTreehouse/maplib_workshop/pan#>.\n",
    "@prefix tpl:<https://github.com/DataTreehouse/maplib_workshop/templates#>.\n",
    "@prefix xsd:<http://www.w3.org/2001/XMLSchema#>.\n",
    "\n",
    "tpl:type_labels [ ] :: {\n",
    "  ottr:Triple(pan:Entity,rdfs:label,\"Entity\"),\n",
    "  ottr:Triple(pan:Address,rdfs:label,\"Address\"),\n",
    "  ottr:Triple(pan:Intermediary,rdfs:label,\"Intermediary\"),\n",
    "  ottr:Triple(pan:Officer,rdfs:label,\"Officer\"),\n",
    "  ottr:Triple(pan:Other,rdfs:label,\"Other\"),\n",
    "} .\n",
    "\n",
    "tpl:entities [ xsd:anyURI ?node_id, ??name, ??incorporation_date, \n",
    "               ??inactivation_date, ??struck_off_date, ??status, \n",
    "               ??country, ??service_provider ] :: {\n",
    "  tpl:named_node(?node_id, ?name, pan:Entity),\n",
    "  ottr:Triple(?node_id,pan:incorporation_date,?incorporation_date) ,\n",
    "  ottr:Triple(?node_id,pan:inactivation_date,?inactivation_date) ,\n",
    "  ottr:Triple(?node_id,pan:struck_off_date,?struck_off_date) ,\n",
    "  ottr:Triple(?node_id,pan:status,?status) ,\n",
    "  tpl:country(?node_id, ?country) ,\n",
    "  ottr:Triple(?node_id,pan:service_provider,?service_provider)\n",
    "} . \n",
    "\n",
    "tpl:addresses [ xsd:anyURI ?node_id, ?address, ??country ] :: {\n",
    "  tpl:named_node(?node_id, ?address, pan:Address),\n",
    "  ottr:Triple(?node_id, rdfs:label, ?address),\n",
    "  ottr:Triple(?node_id, pan:address, ?address),\n",
    "  tpl:country(?node_id, ?country)\n",
    "} . \n",
    "\n",
    "tpl:intermediaries [ xsd:anyURI ?node_id, ??name, ??status, ??country ] :: {\n",
    "  tpl:named_node(?node_id, ?name, pan:Intermediary),\n",
    "  ottr:Triple(?node_id,pan:status,?status) ,\n",
    "  tpl:country(?node_id, ?country)\n",
    "} . \n",
    "\n",
    "tpl:officers [ xsd:anyURI ?node_id, ??name, ??country ] :: {\n",
    "  tpl:named_node(?node_id, ?name, pan:Officer),\n",
    "  tpl:country(?node_id, ?country)\n",
    "} . \n",
    "\n",
    "tpl:others [ xsd:anyURI ?node_id, ??name, ??country ] :: {\n",
    "  tpl:named_node(?node_id, ?name, pan:Other),\n",
    "  tpl:country(?node_id, ?country),\n",
    "} . \n",
    "\n",
    "tpl:relationships [xsd:anyURI ?node_id_start, xsd:anyURI ?node_id_end, ?rel_type] :: {\n",
    "    ottr:Triple(?node_id_start, ?rel_type, ?node_id_end),\n",
    "} .\n",
    "\n",
    "tpl:specific_relationships [xsd:anyURI ?node_id_start, xsd:anyURI ?node_id_end, ?link] :: {\n",
    "    ottr:Triple(?node_id_start, ?link, ?node_id_end),\n",
    "} .\n",
    "\n",
    "tpl:named_node [ ?node_id, ?name, ?type ] :: {\n",
    "  tpl:node(?node_id, ?type),\n",
    "  ottr:Triple(?node_id, rdfs:label, ?name),\n",
    "} .\n",
    "\n",
    "tpl:node [?node_id, ?type] :: {\n",
    "    ottr:Triple(?node_id, a, pan:Node),\n",
    "    ottr:Triple(?node_id, a, ?type),\n",
    "} . \n",
    "\n",
    "tpl:country [?node_id, ?country] :: {\n",
    "  cross | ottr:Triple(?node_id, pan:country, ++?country)\n",
    "} .\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35eaf569",
   "metadata": {},
   "source": [
    "### We create a mapping object (a graph) based on our templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875f29d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Mapping([doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e1e187",
   "metadata": {},
   "source": [
    "### We can now expand the templates with the tables / DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ceba3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.expand(\"tpl:type_labels\")\n",
    "m.expand(\"tpl:entities\", entities_df, [\"node_id\"])\n",
    "m.expand(\"tpl:addresses\", addresses_df, [\"node_id\"])\n",
    "m.expand(\"tpl:intermediaries\", intermediaries_df, [\"node_id\"])\n",
    "m.expand(\"tpl:officers\", officers_df, [\"node_id\"])\n",
    "m.expand(\"tpl:others\", others_df, [\"node_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2f7513",
   "metadata": {},
   "outputs": [],
   "source": [
    "relcols=[\"node_id_start\", \"node_id_end\", \"rel_type\"]\n",
    "m.expand(\"tpl:relationships\", relationships_df[relcols], relcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31be8220",
   "metadata": {},
   "outputs": [],
   "source": [
    "relcols=[\"node_id_start\", \"node_id_end\", \"link\"]\n",
    "m.expand(\"tpl:specific_relationships\", relationships_df[relcols].drop_nulls(\"link\"), relcols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa5cfc8",
   "metadata": {},
   "source": [
    "### We have a look at the different relationship types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570bf619",
   "metadata": {},
   "outputs": [],
   "source": [
    "relationships_df[\"rel_type\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4411ee",
   "metadata": {},
   "source": [
    "### We are immediately able to query the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63509206",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = m.query(\"\"\"\n",
    "PREFIX pan:<https://github.com/DataTreehouse/maplib_workshop/pan#>\n",
    "PREFIX rdfs:<http://www.w3.org/2000/01/rdf-schema#>\n",
    "SELECT ?oname ?cname WHERE {\n",
    "    ?officer a pan:Officer .\n",
    "    ?officer rdfs:label ?oname .\n",
    "    ?officer pan:officer_of ?c .\n",
    "    ?c rdfs:label ?cname .\n",
    "    ?officer pan:country \"Norway\" .\n",
    "}\n",
    "\"\"\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19503721",
   "metadata": {},
   "source": [
    "### Query results are again DataFrames, which we can manipulate further. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18907234",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(pl.col(\"cname\").str.to_lowercase().str.contains(\"wilh\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411d226d",
   "metadata": {},
   "source": [
    "### Let's find all Norwegian officers, ordered by the number of companies they are officers of (descending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1671d7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.query(\"\"\"\n",
    "PREFIX pan:<https://github.com/DataTreehouse/maplib_workshop/pan#>\n",
    "PREFIX rdfs:<http://www.w3.org/2000/01/rdf-schema#>\n",
    "SELECT ?officer ?oname (COUNT(?cname) as ?ccount) WHERE {\n",
    "    ?officer a pan:Officer .\n",
    "    ?officer rdfs:label ?oname .\n",
    "    ?officer pan:officer_of ?c .\n",
    "    ?c rdfs:label ?cname .\n",
    "    ?officer pan:country \"Norway\" .\n",
    "}\n",
    "GROUP BY ?oname ?officer\n",
    "ORDER BY DESC(?ccount)\n",
    "LIMIT 20\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4141dd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just a backup.. \"https://github.com/DataTreehouse/maplib_workshop/node_ids#80063253\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f051a338",
   "metadata": {},
   "source": [
    "### Finally, we can write 2,7 GB of triples.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779cf331",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.write_ntriples(\"leaks.nt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
